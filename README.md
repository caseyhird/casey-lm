# casey-lm


todo:
- add readme details
- allow options for tokenization method, attention type, norm type, activation function, positional encoding, dataset, optimizer, scheduler, and other hyperparameters
- other impls: tinygrad, scratch, lua torch, julia mlj, julia flux
- More sophisticated architecture (maybe)
- Edge optimized version
- Pruning, quantization, etc.
- Distributed training