{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/crhird/Documents/Projects/casey-lm/casey-lm/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 67349/67349 [00:02<00:00, 25322.64 examples/s]\n",
      "Map: 100%|██████████| 872/872 [00:00<00:00, 26540.83 examples/s]\n",
      "Map: 100%|██████████| 1821/1821 [00:00<00:00, 27462.74 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "max_length = 128\n",
    "\n",
    "dataset = load_dataset('glue', 'sst2')\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_examples(examples):\n",
    "    return tokenizer(examples['sentence'], truncation=True, padding='max_length', max_length=max_length)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_examples, batched=True)\n",
    "\n",
    "# Used to create batches of tokens\n",
    "def data_collator(features): \n",
    "    input_ids = [f['input_ids'] for f in features]\n",
    "    return torch.tensor(input_ids)\n",
    "\n",
    "train_dataloader = DataLoader(tokenized_dataset['train'].shuffle(seed=42), batch_size=batch_size, collate_fn=data_collator)\n",
    "val_dataloader = DataLoader(tokenized_dataset['validation'].shuffle(seed=42), batch_size=batch_size, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import torch\n",
    "from model.torch_impl.language_model import TorchLanguageModel, LanguageModelConfig\n",
    "\n",
    "def do_train():\n",
    "    model = TorchLanguageModel(LanguageModelConfig(**{\n",
    "        'vocab_size': tokenizer.vocab_size,\n",
    "        'context_length': max_length,\n",
    "        'embedding_dim': 8,\n",
    "        'num_decoder_layers': 3,\n",
    "        'num_heads': 2,\n",
    "        'dim_feedforward': 32,\n",
    "        'dropout': 0.1,\n",
    "    }))\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(10):\n",
    "        model.train()\n",
    "        iters = 0\n",
    "        for batch in tqdm.tqdm(train_dataloader):\n",
    "            inputs = batch[:, :-1]\n",
    "            labels = batch[:, 1:]\n",
    "            optimizer.zero_grad()\n",
    "            output = model(inputs)\n",
    "            loss = criterion(output.view(-1, tokenizer.vocab_size), labels.flatten())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            iters += 1\n",
    "            if iters > 50:\n",
    "                break\n",
    "        \n",
    "        model.eval()\n",
    "        iters = 0\n",
    "        with torch.no_grad():\n",
    "            total_correct = 0\n",
    "            for batch in val_dataloader:\n",
    "                inputs = batch[:, :-1]\n",
    "                labels = batch[:, 1:]\n",
    "                output = model(inputs)\n",
    "                _, predicted = torch.max(output, dim=2)\n",
    "                total_correct += (predicted == labels).sum().item()\n",
    "                iters += 1\n",
    "                if iters > 10:\n",
    "                    break\n",
    "            accuracy = total_correct / len(val_dataloader.dataset)\n",
    "            print(f'Epoch {epoch+1}, Validation Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 50/2105 [00:27<18:57,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation Accuracy: 41.4702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 50/2105 [00:27<19:01,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Validation Accuracy: 41.4702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 50/2105 [00:28<19:17,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Validation Accuracy: 41.4702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 50/2105 [00:27<19:08,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Validation Accuracy: 41.4702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 50/2105 [00:27<18:56,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Validation Accuracy: 41.4702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 50/2105 [00:28<19:19,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Validation Accuracy: 41.4702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 50/2105 [00:28<19:26,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Validation Accuracy: 41.4702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 50/2105 [00:28<19:27,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Validation Accuracy: 41.4702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 50/2105 [00:28<19:22,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Validation Accuracy: 41.4702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 50/2105 [00:28<19:36,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Validation Accuracy: 41.4702\n"
     ]
    }
   ],
   "source": [
    "# TODO: not yet certain that the model is working as intended or that training is well behaved\n",
    "\n",
    "do_train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "casey-lm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
